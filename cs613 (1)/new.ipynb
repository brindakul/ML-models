{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Tcsritmu6fY"
   },
   "source": [
    "# Homework 1\n",
    "\n",
    "Name <br>\n",
    "CS 613 Machine Learning <br>\n",
    "Fall 2021 <br>\n",
    "Dr. Edward Kim <br>\n",
    "Drexel University <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAhSm--aqaS2"
   },
   "source": [
    "# Submission\n",
    "---\n",
    "### __Question 1 Part 1:__ <br>\n",
    "\n",
    "\n",
    "### __Question 1 Part 2:__ <br>\n",
    "\n",
    "a. \n",
    "        \n",
    "b.\n",
    "\n",
    "c.\n",
    "\n",
    "\n",
    "### __Question 2__ <br>\n",
    "\n",
    "a.\n",
    "\n",
    "b.\n",
    "\n",
    "\n",
    "### __Question 3__ <br>\n",
    "\n",
    "a. \n",
    "\n",
    "\n",
    "### __Question 4__ <br>\n",
    "\n",
    "a. \n",
    "\n",
    "\n",
    "### __Question 5__ <br>\n",
    "\n",
    "a. \n",
    " \n",
    "b. \n",
    "\n",
    "c. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOVoKK09vebK"
   },
   "source": [
    "# Introduction\n",
    "In this assignment you will perform linear regression on a dataset and using cross-validation to analyze your results. In addition to computing and applying the close-form solution, you will also implement from scratch a gradient descent algorithm for linear regression.\n",
    "As with all homeworks, you cannot use any functions that are against the “spirit” of the assignment, unless explicitly told to do so. For this assignment that would mean any linear regression functions. You may use statistical and linear algebra functions to do things like:\n",
    "\n",
    "• mean\n",
    "\n",
    "• std\n",
    "\n",
    "• cov\n",
    "\n",
    "• inverse\n",
    "\n",
    "• matrix multiplication\n",
    "\n",
    "• transpose\n",
    "\n",
    "• etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mocQvJz1vsbP"
   },
   "source": [
    "### Datasets\n",
    "Fish Length Dataset (x06Simple.csv) This dataset consists of 44 rows of data each of the form:\n",
    "1. Index\n",
    "2. Age (days)\n",
    "3. Temperature of Water (degrees Celsius) \n",
    "4. Length of Fish\n",
    "\n",
    "The first row of the data contains header information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "lQB73EqcuzCA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKOqZga_gh1-"
   },
   "source": [
    "# 1. Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {
    "id": "wleQRC19u5eP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "feature = [-2, -5, -3, 0, -6, -2, 1, 5, -1, 3]\n",
    "label = [1, -4, 1, 3, 11, 5, 0, -1, -3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardise(string1):\n",
    "    m1=np.mean(string1)\n",
    "    std1=np.std(string1)\n",
    "    string2=(string1-m1)/std1\n",
    "    return string2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(alg):\n",
    "    ones = np.ones(alg.shape[0]).reshape(alg.shape[0], 1)\n",
    "    alg=np.concatenate((ones, alg),1)\n",
    "    #print(alg)\n",
    "    return alg#print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_prep(V):\n",
    "    V1=Standardise(V)\n",
    "    V2=add_bias(V1)\n",
    "    return V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4       ],\n",
       "       [-1.42639945]])"
      ]
     },
     "execution_count": 1143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def least_square_estimate(X,Y):\n",
    "    X21=Standardise(X)\n",
    "    X11=add_bias(X21)\n",
    "    X12=X11.transpose()  \n",
    "    theta=np.linalg.inv(X12 @ X11) @ X12 @ Y\n",
    "    return theta\n",
    "X1=np.array(feature)\n",
    "Y1=np.array(label)\n",
    "least_square_estimate(X1.reshape(-1,1),Y1.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.31008684]\n",
      " [ 1.         -1.24034735]\n",
      " [ 1.         -0.62017367]\n",
      " [ 1.          0.31008684]\n",
      " [ 1.         -1.55043418]\n",
      " [ 1.         -0.31008684]\n",
      " [ 1.          0.62017367]\n",
      " [ 1.          1.86052102]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          1.24034735]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression #Importing linear regression model and mean squared error from sklearn library\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "model= LinearRegression() \n",
    "X11=initial_prep(X1.reshape(-1, 1))\n",
    "model.fit(X11,Y1.reshape(-1, 1))\n",
    "print(X11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -1.42639945]\n",
      "[1.4]\n"
     ]
    }
   ],
   "source": [
    "print(model.coef_[0])\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Xct5skngoB0"
   },
   "source": [
    "(a) Compute the coefficients for the linear regression using least squares estimate (LSE), where the second value (column) is the dependent variable (the value to be predicted) and the first column is the sole feature. Show your work and remember to add a bias feature and to standardize the features. Compute this model using all of the data (don’t worry about separating into training and testing sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  (b)  Confirm your coefficient and intercept term using the sklearn.linear model LinearRegression function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hx1RGZI9sFrK"
   },
   "source": [
    "## Question 1 Part 2. For the function $g(x) = (x − 1)^4$, where x is a single value (not a vector or matrix):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) (3pts) What is the gradient with respect to x? Show your work to support your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g(x)=(x-1)^4\n",
    "g'(x)=4(x-1)^3\n",
    "Considering g'(x)=0\n",
    "    4(x-1)^3 =0\n",
    "    (x-1)^3=0\n",
    "    x-1=0\n",
    "    x=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) (3pts) What is the global minima for g(x)? Show your work to support your answer. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2(c)'></a>\n",
    "\n",
    "#### 1.2(c)\n",
    "\n",
    "(3pts) Plot x vs g(x) using matplotlib and use this image in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x1=3\n",
    "y1=(x1-1)**4\n",
    "#plt.plot([1, 2, 3, 4])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('g(x)')\n",
    "plt.plot([1, 2, 3, 4], [0, 1, 16, 81], linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdkyJhqaiEZ3"
   },
   "source": [
    "# 2. Closed Form Linear Regression\n",
    "\n",
    "Download the dataset x06Simple.csv from Blackboard. This dataset has header information in its first row and then all subsequent rows are in the format:\n",
    "\n",
    "ROW $Id,x_{i,1},x_{i,2}, y_i$\n",
    "\n",
    "Your code should work on any CSV data set that has the first column be header information, the first column be some integer index, then D columns of real-valued features, and then ending with a target value.\n",
    "\n",
    "__Write a script that:__\n",
    "\n",
    "1. Reads in the data, ignoring the first row (header) and first column (index).\n",
    "2. Randomizes the data\n",
    "3. Selects the first 2/3 (round up) of the data for training and the remaining for testing\n",
    "4. Standardizes the data (except for the last column of course) using the training data\n",
    "5. Computes the closed-form solution of linear regression\n",
    "6. Applies the solution to the testing samples\n",
    "7. Computes the root mean squared error (RMSE):  $\\sqrt{\\frac{1}{N}\\sum_{i=1}^N (Y_i-\\hat{Y_i})^2}$. Where $\\hat{Y_i}$ is the predicted\n",
    "value for observation $X_i$.\n",
    "\n",
    "__Implementation Details__\n",
    "1. Seed the random number generate with zero prior to randomizing the data \n",
    "2. Don’t forget to add in a bias feature!\n",
    "\n",
    "__In your report you will need:__\n",
    "1. The final model in the form $y=\\theta_0+\\theta_1x_{:,1} + ...$\n",
    "2. The root mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "dataset=pd.read_csv(\"x06Simple(1).csv\")\n",
    "dataset=dataset.drop(dataset.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(dataset)\n",
    "df1 = df1.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training set: 29\n",
      "No. of testing set: 15\n"
     ]
    }
   ],
   "source": [
    "train = df1.sample(frac=0.66, random_state=42)\n",
    "test = df1.drop(train.index)\n",
    "print(f\"No. of training set: {train.shape[0]}\")\n",
    "print(f\"No. of testing set: {test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Ages 83.18181818181819\n",
      "Mean of Temp of Water 28.0\n",
      "Standard Deviation1 47.69684788803366\n",
      "Standard Deviation2 2.0059364927239987\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "m1=df1['Age'].mean()\n",
    "m2=df1['Temp of Water'].mean()\n",
    "sd1=np.std(train['Age'])\n",
    "sd2=np.std(train['Temp of Water'])\n",
    "print(\"Mean of Ages\",m1)\n",
    "print(\"Mean of Temp of Water\",m2)\n",
    "print(\"Standard Deviation1\",sd1)\n",
    "print(\"Standard Deviation2\",sd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise(x):\n",
    "    return (x - m1)/sd1\n",
    "def standardise1(x):\n",
    "    return (x - m2)/sd2\n",
    "y11=train['Length of Fish']\n",
    "x11=train.drop(['Length of Fish'],axis=1)\n",
    "train['Age']=train['Age'].apply(standardise)\n",
    "train['Temp of Water']=train['Temp of Water'].apply(standardise1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=train['Length of Fish']\n",
    "train=train.drop(['Length of Fish'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(train.shape[0]).reshape(train.shape[0], 1)\n",
    "train=np.concatenate((ones, train),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt=train.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3142.71289532, 1282.76512765, -185.44219176])"
      ]
     },
     "execution_count": 1227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=train_y.to_numpy()\n",
    "theta=np.linalg.inv(Xt @ train) @ Xt @ Y\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "0   5112.858698\n",
      "1   1559.468303\n",
      "2   2853.751955\n",
      "3   3237.000771\n",
      "4   1915.822991\n",
      "5   4168.198709\n",
      "6   2483.965189\n",
      "7   1566.199328\n",
      "8   3606.787536\n",
      "9   1004.788155\n",
      "10  1381.305945\n",
      "11  4921.234290\n",
      "12  4736.340908\n",
      "13  4743.071933\n",
      "14  2107.447399\n",
      "15  3798.411944\n",
      "16  4174.929734\n",
      "17  2477.234164\n",
      "18  4927.965316\n",
      "19  4551.447525\n",
      "20  3230.269745\n",
      "21  3983.305326\n",
      "22  5297.752081\n",
      "23  2100.716373\n",
      "24  4544.716500\n",
      "25  1189.681537\n",
      "26  1374.574920\n",
      "27  2668.858572\n",
      "28  3421.894153\n",
      "----\n",
      "21    4600\n",
      "0      620\n",
      "15    3255\n",
      "39    3030\n",
      "24    2140\n",
      "7     4465\n",
      "37    2710\n",
      "23    1305\n",
      "17    4315\n",
      "33     590\n",
      "34    1205\n",
      "9     4570\n",
      "20    4600\n",
      "43    3214\n",
      "36    2140\n",
      "29    4520\n",
      "30    4525\n",
      "14    2805\n",
      "32    4566\n",
      "31    4565\n",
      "16    4015\n",
      "18    4495\n",
      "10    4600\n",
      "13    2110\n",
      "8     4530\n",
      "22     590\n",
      "11     625\n",
      "26    3920\n",
      "28    4515\n",
      "Name: Length of Fish, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred=np.dot(train,theta)\n",
    "df5=pd.DataFrame(y_pred)\n",
    "print(df5)\n",
    "print(\"----\")\n",
    "print(y11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Temp of Water</th>\n",
       "      <th>Length of Fish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>83</td>\n",
       "      <td>31</td>\n",
       "      <td>3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83</td>\n",
       "      <td>25</td>\n",
       "      <td>3535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>125</td>\n",
       "      <td>31</td>\n",
       "      <td>3180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>83</td>\n",
       "      <td>29</td>\n",
       "      <td>3920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>111</td>\n",
       "      <td>31</td>\n",
       "      <td>3040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>25</td>\n",
       "      <td>2120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>2890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>125</td>\n",
       "      <td>27</td>\n",
       "      <td>4535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>25</td>\n",
       "      <td>3110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97</td>\n",
       "      <td>25</td>\n",
       "      <td>3935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>139</td>\n",
       "      <td>31</td>\n",
       "      <td>3257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Temp of Water  Length of Fish\n",
       "1    28             25            1315\n",
       "38   83             31            3020\n",
       "5    83             25            3535\n",
       "41  125             31            3180\n",
       "27   83             29            3920\n",
       "40  111             31            3040\n",
       "2    41             25            2120\n",
       "25   55             29            2890\n",
       "35   41             31            1915\n",
       "19  125             27            4535\n",
       "12   28             27            1215\n",
       "4    69             25            3110\n",
       "6    97             25            3935\n",
       "3    55             25            2600\n",
       "42  139             31            3257"
      ]
     },
     "execution_count": 1229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise(x):\n",
    "\treturn (x - m1)/sd1\n",
    "def standardise1(x):\n",
    "\treturn (x - m2)/sd2\n",
    "y12=test['Length of Fish']\n",
    "test=test.drop(['Length of Fish'],axis=1)\n",
    "test['Age']=test['Age'].apply(standardise)\n",
    "test['Temp of Water']=test['Temp of Water'].apply(standardise1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones1 = np.ones(test.shape[0]).reshape(test.shape[0], 1)\n",
    "test=np.concatenate((ones1, test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.dot(test,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     1315\n",
       "38    3020\n",
       "5     3535\n",
       "41    3180\n",
       "27    3920\n",
       "40    3040\n",
       "2     2120\n",
       "25    2890\n",
       "35    1915\n",
       "19    4535\n",
       "12    1215\n",
       "4     3110\n",
       "6     3935\n",
       "3     2600\n",
       "42    3257\n",
       "Name: Length of Fish, dtype: int64"
      ]
     },
     "execution_count": 1233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square error 527.4257402997022\n"
     ]
    }
   ],
   "source": [
    "rm=y_test-y12\n",
    "rms=rm**2\n",
    "n=rms.shape[0]\n",
    "rms_er=np.sum(rms)/n\n",
    "print(\"Root Mean Square error\",np.sqrt(rms_er))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 620 1315 2120 2600 3110 3535 3935 4465 4530 4570 4600  625 1215 2110\n",
      " 2805 3255 4015 4315 4495 4535 4600 4600  590 1305 2140 2890 3920 3920\n",
      " 4515 4520 4525 4565 4566  590 1205 1915 2140 2710 3020 3030 3040 3180\n",
      " 3257 3214]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"x06Simple(1).csv\")\n",
    "data= data.drop(data.columns[0], axis=1)\n",
    "#print(data)\n",
    "X = data.iloc[:, :-1].values # copy all columns excluding last column\n",
    "Y = data['Length of Fish'].values   # copy the last column only\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1/3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4495 3255  590 4015 3040 4530 2110 3535 4315 4566 2805 1915 4465 1205\n",
      " 1315 3920 1215  590 2140 3935 1305 2140 4600 4535 4570 3030 3257 2600\n",
      "  620]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression #Importing linear regression model and mean squared error from sklearn library\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "model= LinearRegression() \n",
    "model.fit(X_train,Y_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4110.65658101 2331.93076653 2958.84495836 3060.86171937 5364.48496467]\n",
      "[4525 2710 3920 3110 4600 2890 4515  625 3020 4565 4520 4600 3180 2120\n",
      " 3214]\n"
     ]
    }
   ],
   "source": [
    "print (prediction[0:5])\n",
    "print (Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean square error using model 703.6080211313106\n",
      "Root mean square error for test data 527.4257402997022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse=mean_squared_error(Y_test,prediction)\n",
    "print(\"Root Mean square error using model\",math.sqrt(mse))\n",
    "mse=mean_squared_error(y12,y_test)\n",
    "print(\"Root mean square error for test data\",math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnobwYLRnJ9h"
   },
   "source": [
    "# 3. S-Folds Cross-Validation\n",
    "\n",
    "Cross-Validation is a technique used to get reliable evaluation results when we don’t have that much data (and it is therefore difficult to train and/or test a model reliably).\n",
    "\n",
    "In this section you will do S-Folds Cross-Validation for a few different values of S. For each run you will divide your data up into S parts (folds) and test S different models using S-Folds Cross-Validation and evaluate via root mean squared error. In addition, to observe the affect of system variance, we will repeat these experiments several times (shuffling the data each time prior to creating the folds). We will again be doing our experiment on the provided fish dataset. You may use sklearn KFold to perform this task.\n",
    "\n",
    "__Write a script that:__\n",
    "\n",
    "1. Reads in the data, ignoring the first row (header) and first column (index).\n",
    "2. 20 times does the following: <br>\n",
    " (a) Randomizes the data <br>\n",
    " (b) Creates S folds. <br>\n",
    " (c) For i= 1 to S <br>\n",
    "        i. Select fold i as your testing data and the remaining (S − 1) folds as your training data \n",
    "        ii. Standardizes the data (except for the last column of course) based on the training data\n",
    "        iii. Train a closed-form linear regression model \n",
    "        iv. Compute the squared error for each sample in the current testing fold\n",
    " (d) You should now have N squared errors. Compute the RMSE for these.\n",
    "3. You should now have 20 RMSE values. Compute the mean and standard deviation of these. The former should give us a better “overall” mean, whereas the latter should give us feel for the variance of the models that were created.\n",
    "\n",
    "\n",
    "__Implementation Details__\n",
    "1. Don’t forget to add a bias feature!\n",
    "2. When you randomize your data, you may want to set your random seed value so you do not have the same randomly shuffled data! This can also be achieved via KFold random state\n",
    "\n",
    "__In your report you will need:__\n",
    "1. The average and standard deviation of the root mean squared error for S = 3 over the 20 different seed values..\n",
    "2. The average and standard deviation of the root mean squared error for S = 5 over the 20 different seed values.\n",
    "3. The average and standard deviation of the root mean squared error for S = 20 over 20 different seed values.\n",
    "4. The average and standard deviation of the root mean squared error for S = N (where N is the number of samples) over 20 different seed values. This is basically leave-one-out cross- validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "dataset=pd.read_csv(\"x06Simple(1).csv\")\n",
    "dataset=dataset.drop(dataset.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardise(string1):\n",
    "    m1=np.mean(string1)\n",
    "    std1=np.std(string1)\n",
    "    string1=(string1-m1)/std1\n",
    "    return string1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(X):\n",
    "    ones = np.ones(X.shape[0]).reshape(X.shape[0], 1)\n",
    "    ones1=ones.T\n",
    "    X_train1=np.concatenate((ones, X),1)\n",
    "    return X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_error(y12,y_test):\n",
    "    rm=y_test-y12\n",
    "    rms=rm**2\n",
    "    #n=rms.shape[0]\n",
    "    #rms_er=np.sum(rms)\n",
    "    return rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrossvalidation(S):\n",
    "    n=20\n",
    "    df1 = pd.DataFrame(dataset)\n",
    "    #df1 = df1.sample(frac = 1)    \n",
    "    y_train=df1['Length of Fish']\n",
    "    df1=df1.drop('Length of Fish',axis=1)\n",
    "    np0=df1.to_numpy()\n",
    "    np1=y_train.to_numpy()\n",
    "    rms1=0\n",
    "    while n!=0:\n",
    "        rs1=0\n",
    "        t1 = 0\n",
    "        np.random.seed(1)\n",
    "        np.random.shuffle(np0)\n",
    "        kf = KFold(n_splits=S)\n",
    "        #testerr = np.zeros((1,1)).reshape(-1,1)\n",
    "        for train,test in kf.split(np0):\n",
    "            Y_train=np1[train]\n",
    "            X_train=np0[train]\n",
    "            X_train1=Standardise(X_train)\n",
    "            X_train2=add_bias(X_train1)\n",
    "            Xt=X_train2.transpose() \n",
    "            theta=np.linalg.inv(Xt @ X_train2)@ Xt @Y_train\n",
    "            #print(theta)\n",
    "            X_test=np0[test]\n",
    "            Y_test=np1[test]\n",
    "            #print(Y_test)\n",
    "            X_test1=Standardise(X_test)\n",
    "            X_test2=add_bias(X_test1)\n",
    "            Y_pred=np.dot(X_test2,theta)\n",
    "            rs1 = rs1 + np.sum(rms_error(Y_test,Y_pred))\n",
    "            #print(testerr.shape[0], rs2)\n",
    "            #testerr = np.hstack(testerr,rs2.reshape(-1,1))\n",
    "            t1=t1+Y_pred.shape[0]\n",
    "            #print(t1,rs1,Y_pred.shape)\n",
    "            \n",
    "        rmse = np.sqrt(rs1/t1)\n",
    "        #rm1=np.mean(t)\n",
    "        #print(rmse)\n",
    "        #rms1.append(rmse)\n",
    "        \n",
    "        #rms=np.sqrt(rm1)\n",
    "        rms1=rmse+rms1\n",
    "        n=n-1\n",
    "    print(\"Mean\",rms1/20)\n",
    "    print(\"Std deviation\",rms1.std())\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510.4685564831962\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "Scrossvalidation(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1459.2671927825813\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "Scrossvalidation(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1732.801961988905\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "Scrossvalidation(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eqQ15iQomJj"
   },
   "source": [
    "# 4. Locally-Weighted Linear Regression\n",
    "\n",
    "Next we’ll do locally-weighted closed-form linear regression. You may use sklearn train test split\n",
    "for this part.\n",
    "\n",
    "__Write a script to:__\n",
    "1. Read in the data, ignoring the first row (header) and first column (index).\n",
    "2. Randomize the data\n",
    "3. Select the first 2/3 of the data for training and the remaining for testing\n",
    "4. Standardize the data (except for the last column of course) using the training data\n",
    "5. Then for each testing sample <br>\n",
    "(a) Compute the necessary distance matrices relative to the training data in order to compute a local model. <br>\n",
    "(b) Evaluate the testing sample using the local model. <br>\n",
    "(c) Compute the squared error of the testing sample. <br>\n",
    "6. Computes the root mean squared error  $\\sqrt{\\frac{1}{N}\\sum_{i=1}^N (Y_i-\\hat{Y_i})^2}$. Where $\\hat{Y_i}$ is the predicted value for observation Xi.\n",
    "\n",
    "__Implementation Details__\n",
    "1. Seed the random number generate with zero prior to randomizing the data\n",
    "2. Don’t forget to add in the bias feature!\n",
    "3. Use the L1 distance when computing the distances d(a, b).\n",
    "−d(a,b)/k2\n",
    "5. Use all training instances when computing the local model.\n",
    "\n",
    "__In your report you will need:__\n",
    "1. The root mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "dataset=pd.read_csv(\"x06Simple(1).csv\")\n",
    "dataset=dataset.drop(dataset.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(dataset)\n",
    "df1 = df1.sample(frac = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training set: 29\n",
      "No. of testing set: 15\n"
     ]
    }
   ],
   "source": [
    "train = df1.sample(frac=0.66, random_state=42)\n",
    "test = df1.drop(train.index)\n",
    "print(f\"No. of training set: {train.shape[0]}\")\n",
    "print(f\"No. of testing set: {test.shape[0]}\")\n",
    "#print(train)\n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(['Length of Fish'],axis=1)\n",
    "X_train=train.to_numpy()\n",
    "Y_train=test.to_numpy()\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(X_train)\n",
    "np.random.shuffle(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardise(string1):\n",
    "    #print(string1)\n",
    "    m1=np.mean(string1)\n",
    "    std1=np.std(string1)\n",
    "    string1=(string1-m1)/std1\n",
    "    #print(string1)\n",
    "    return string1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1=Standardise(X_train[:,0])\n",
    "X_2=Standardise(X_train[:,1])\n",
    "X_train1=np.array([X_1,X_2])\n",
    "X_train1=X_train1.T()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(X_train1.shape[0]).reshape(X_train1.shape[0], 1)\n",
    "ones1=ones.T\n",
    "X_train1=np.concatenate((ones, X_train1),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740.025157088527\n"
     ]
    }
   ],
   "source": [
    "def l1_distance(a, b):\n",
    "    return sum(abs(e1-e2) for e1, e2 in zip(a,b))\n",
    "X_test=test.to_numpy()\n",
    "for i in range (X_train.shape[0]):\n",
    "    w = l1_distance(X_train1[i],Y_train)\n",
    "print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPsXfZskpteA"
   },
   "source": [
    "# 5. Gradient Descent\n",
    "\n",
    "As discussed in class Gradient Descent (Ascent) is a general algorithm that allows us to converge on local minima (maxima) when a closed-form solution is not available or is not feasible to compute.\n",
    "\n",
    "In this section you are going to implement a gradient descent algorithm to find the parameters for linear regression on the same data used for the previous sections. You may NOT use any function for a ML library to do this for you, except sklearn train test split for the data.\n",
    "\n",
    "__Write a script that:__\n",
    "1. Reads in the data, ignoring the first row (header) and first column (index).\n",
    "2. Randomizes the data\n",
    "3. Selects the first 2/3 (round up) of the data for training and the remaining for testing\n",
    "4. Standardizes the data (except for the last column of course) base on the training data\n",
    "5. While the termination criteria (mentioned above in the implementation details) hasn’t been met\n",
    "(a) Compute the RMSE of the training data\n",
    "(b) While we can’t let the testing set affect our training process, also compute the RMSE of\n",
    "the testing error at each iteration of the algorithm (it’ll be interesting to see). \n",
    "(c) Update each parameter using batch gradient descent\n",
    "6. Compute the RMSE of the testing data.\n",
    "\n",
    "__Implementation Details__\n",
    "1. Seed the random number generator prior to your algorithm.\n",
    "2. Don’t forget to a bias feature!\n",
    "3. Initialize the parameters of θ using random values in the range [-1, 1]\n",
    "4. Do batch gradient descent  --- the gradient with respect to all of the data\n",
    "5. Terminate when absolute value of the percent change in the RMSE on the training data is less than $2^{−23}$, or after 1,000 iterations have passed (whichever occurs first).\n",
    "6. Use a learning rate $\\eta=0.01$..\n",
    "7. Make sure that you code can work for an arbitrary number of observations and an arbitrary number of features.\n",
    "\n",
    "__What you will need for your report__\n",
    "1. Final model\n",
    "2. A graph of the RMSE of the training and testing sets as a function of the iteration \n",
    "3. The final RMSE testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "dataset=pd.read_csv(\"x06Simple(1).csv\")\n",
    "dataset=dataset.drop(dataset.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(dataset)\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training set: 29\n",
      "No. of testing set: 15\n"
     ]
    }
   ],
   "source": [
    "train = df1.sample(frac=0.66, random_state=42)\n",
    "test = df1.drop(train.index)\n",
    "print(f\"No. of training set: {train.shape[0]}\")\n",
    "print(f\"No. of testing set: {test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=train['Length of Fish']\n",
    "X_train=train.drop(['Length of Fish'],axis=1)\n",
    "X=X_train.to_numpy()\n",
    "Y=y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardise(string1):\n",
    "    m1=np.mean(string1)\n",
    "    std1=np.std(string1)\n",
    "    string1=(string1-m1)/std1\n",
    "    return string1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(X):\n",
    "    ones = np.ones(X.shape[0]).reshape(X.shape[0], 1)\n",
    "    ones1=ones.T\n",
    "    X_train1=np.concatenate((ones, X),1)\n",
    "    return X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x1, y1, alpha=0.001, epsilon=0.0001):\n",
    "    m, n = x1.shape\n",
    "    w_old = np.random.rand(n).reshape(n, 1)\n",
    "    w_new = np.zeros((n, 1))\n",
    "    i = 0\n",
    "    while norm(w_new - w_old)  > epsilon:\n",
    "        w_old = w_new\n",
    "        RSS = compute_error(x1, y1, w_old)\n",
    "        grad_RSS = (X.T.dot(x1).dot(w_old) - X.T.dot(y1))   \n",
    "        w_new = w_old - alpha * grad_RSS\n",
    "        print(i, np.squeeze(RSS))\n",
    "        i += 1\n",
    "    return w_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
